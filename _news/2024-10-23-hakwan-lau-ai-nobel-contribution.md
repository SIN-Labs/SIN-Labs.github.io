---
layout: post
title: "[The Dong-A Ilbo] \"Hassabis Repeatedly Spoke About a Nobel Prize for DeepMind\" Hakwan Lau, Leader of IBS Neuroscience Imaging Research Group"
hero_image: "/assets/images/news.jpg"
hero_title: "News"
image: assets/images/hakwan-lau-ai-nobel-contribution.jpg
date: 2024-10-23
permalink: /news/2024-10-23-hakwan-lau-ai-nobel-contribution/
---
> During my time studying in the UK, I often talked with him… Winning the Nobel Prize proves AI’s contribution to science. The ultimate goal is to develop AI similar to the human brain, and it has been revealed that AI can possess metacognitive abilities, just like humans.

“Demis Hassabis (CEO of Google DeepMind) repeatedly mentioned that DeepMind would win a Nobel Prize, and now it has become a reality.”

Hakwan Lau, the newly appointed leader of the Neuroscience Imaging Research Group at the Institute for Basic Science (IBS), reflected on his discussions with Hassabis during his academic years in the UK. In an interview at Sungkyunkwan University’s campus in Suwon last month, Lau noted the significance of the recent Nobel Prize in Chemistry awarded to Hassabis, along with DeepMind’s John Jumper and David Baker from the University of Washington, for their development of AlphaFold, an AI system that predicts protein structures.

“Despite his humility, Hassabis was always confident that his work would change the world,” Lau said. “This Nobel Prize demonstrates how AI is now making substantial contributions to scientific discovery.”

For Lau, this milestone is closely tied to his own work, which focuses on bridging neuroscience and artificial intelligence. His research aims at developing AI systems that resemble the human brain, a shared ultimate goal for many researchers and tech companies. Lau emphasized that this connection between neuroscience and AI extends beyond innovation—it also addresses the safety of AI systems.

In his recent studies, Lau revealed that AI could possess metacognitive abilities similar to humans—the capacity to evaluate its own knowledge and limitations. Published in *Nature Communications*, his research showed that AI systems could exhibit “positive confidence bias,” a tendency to overestimate their abilities. He proposed methods to measure and correct these biases, emphasizing the importance of such training for widely used AI systems like ChatGPT.

Lau’s vision for IBS involves investigating methods to regulate brain activity patterns and further exploring the overlap between AI and neuroscience. “Continuous collaboration between neuroscience and AI research is essential for developing predictable and reliable AI systems. Such efforts are crucial for ensuring coexistence between humans and artificial intelligence,” Lau concluded.

For more details, [read the full article](https://www.donga.com/news/People/article/all/20241022/130272770/2).
